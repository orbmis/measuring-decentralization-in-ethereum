\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage[
backend=biber,
style=numeric,
sorting=none
]{biblatex}
\addbibresource{bibliography.bib}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{pgfplots}
\pgfplotsset{compat=1.16}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Measuring the Concentration of Control in Contemporary Ethereum}

\author{\IEEEauthorblockN{Simon Brown}
\IEEEauthorblockA{\textit{ConsenSys Software Inc.}\\
simon.brown@consensys.net}
}

\maketitle

\begin{abstract}
Ethereum is undergoing significant changes to its architecture as it evolves.  These changes include its switch to PoS consensus and the introduction of significant infrastructural changes that do not require a change to the core protocol, but that fundamentally affect the way users interact with the network.  These changes represent an evolution toward a more modular architecture, in which there exists new exogenous vectors for centralization.  This paper builds on previous studies of decentralization of Ethereum to reflect these recent significant changes, and Ethereum's new modular paradigm.
\end{abstract}

\begin{IEEEkeywords}
blockchain, Ethereum, decentralization, cryptocurrency, cryptoeconomics, web3
\end{IEEEkeywords}

\section{Introduction}

As web3 and cryptocurrencies are a relatively nascent socio-technological innovation, the broader cryptocurrency ecosystem is in a phase of initial rapid innovation, in which the architecture and topology of the networks are evolving significantly.  This is a well understood phenomenon in technological innovation, which was documented as early as the 1960s \cite{rogers2010diffusion}, in which the innovation and adoption of new technologies develop in an “S-Curve” shape, involving compressed stages of very rapid innovation followed by a period where innovation plateaus for a time.  Ethereum is an example of a technology that is in the rapid innovation phase, in which there are significant changes to the topology of the overall network, both intrinsic and extrinsic to the core protocol.

Previous research \cite{gochhayat2020measuring, lin2021measuring, karakostas2022sok} focused on measuring decentralization at the various layers of a vertical stack within a monolithic system.  The contribution of this paper is a model for measuring decentralization that adapts previous models to Ethereum's contemporary ecosystem topology, allowing for consideration of changes to the overall architecture over time.

The paper is organized as follows: in section II we deliver an overview of how Ethereum is evolving and the challenges faced when attempting to measure its level of decentralization.  In section III we outline the various dimensions that we propose to measure with our model, and our data sources.  In section IV we describe our methodology, including the various indices that are applied to our data.  In section V we deliver a breakdown of results, and we close with our conclusions in section VI.

\section{Background}

It can be argued that protocols that are built on top of the base layer of Ethereum do not pose a direct threat to the base layer itself, even when they are highly centralized, and should therefore not be a factor in quantifying the network's level of decentralization.  Once the base layer is sufficiently decentralized, any number of protocol designs can be implemented on top of it, and ideally the base layer should not be aware of them, or be adversely affected by them.  However, as Ethereum evolves, users increasingly interact with the network through abstracted layers of infrastructure that overlay the core protocol, and as such it can be conversely argued that such protocols could potentially affect the security and/or performance of the overall network under certain conditions, and should therefore be considered within a holistic model of the networks' level of decentralization.   Our criteria for inclusion within our model is that the component being measured does not just serve a single use case or application, but is a protocol through which users interact with an arbitrary number of other dapps and protocols.

Any infrastructure that assumes a significant role in Ethereum can pose a centralization risk to the overall network based on two critical factors:
\begin{enumerate}[label=\alph*.]
\item the size of the infrastructure compared to the base layer, as measured in either percentage of base layer transactions that flow through the infrastructure and/or the Total Value Locked (TVL) compared to the base layer.
\item the potential effect on the base layer should the infrastructure be compromised or develop misaligned incentives, whether this effect is a level of effective degraded performance of the network, or an increased level of censorship.
\end{enumerate}

Ethereum is not a static ecosystem, and other innovations will likely assume a prominent role within the ecosystem in the future, e.g. EigenLayer \cite{eigenlayer2023}, DVT \cite{asgaonkar-2021}.  As such, any model that we develop should account for the changing topology of the ecosystem and allow us to incorporate new infrastructure into the model at a future date, while still being able to track the changes of effective decentralization over time.

\section{Selection of Data Points}

\subsection{Overview of Data Model}

We use as a base for our model the measurement of decentralization in blockchain first described by Balaji Srinivasan as the Minimum Nakamoto coefficient \cite{srinivasan2018}.  This model considers a blockchain network as being composed of a number of subsystems, which are important in terms of maintaining decentralization within an ecosystem, allowing it to remain resistant to capture by any one party or group.  Srinivasan describes any blockchain as being only as decentralized as the least decentralized subsystem, and his original model loosely defines a number of discrete subsystems to measure.

We have adapted Srinivasan's model to the contemporary PoS Ethereum topology and introduced several other dimensions that represent exogenous vectors for potential centralization.  Our model thus extends Srinivasan's original model from 6 dimensions to 15.  These dimensions of measurement are listed below, and are followed by a detailed explanation of the rationale for each.

\vspace{8pt}

\begin{itemize}
   \item \textbf{Based on original Nakamoto Coefficient subsystems:}
   \begin{itemize}
     \item Consensus nodes by client
     \item Consensus nodes by country
     \item Execution nodes by client
     \item Execution nodes by country
     \item Exchanges by supply
     \item Distribution of native asset by amount
     \item Amount staked by pool / staking service provider
   \end{itemize}
   \item \textbf{Metrics pertaining to PBS:}
   \begin{itemize}
       \item Blocks proposed by builder
       \item Blocks proposed by relay
   \end{itemize}
   \item \textbf{Metrics pertaining to Account Abstraction:}
   \begin{itemize}
       \item Number of user operations per bundler
       \item Number of transactions per bundler
   \end{itemize}
   \item \textbf{Miscellaneous Metrics:}
   \begin{itemize}
       \item Effective inflation rate adjusted for burn
       \item Percentage of total supply staked
       \item Layer 2 rollups by relative TVL
       \item Stablecoins by relative TVL
   \end{itemize}
 \end{itemize}

 \vspace{4pt}

\subsection{Metrics based on the Nakamoto Coefficient Subsystems}

We have adapted the Nakamoto Coefficient model through a number of modifications to the original model.  These changes include removing Mining Decentralization and Developer Decentralization. 

The Mining Decentralization metric is longer relevant in PoS Ethereum and as such has been replaced by the ``Amount staked by pool'' metric, which measures the relevant share of the staked ETH by staking service provider. 

The ``Developer Decentralization'' metric is no longer an applicable metric for PoS Ethereum. The rationale for this change is the fact that nodes on the network run a number of different client implementations, each with its own distinct development team.  In this context, and considering a priori that developers are unique to each team, it is sufficient to measure the level of client diversity among nodes on the network rather than the relative contributions of individual developers. 

In terms of client diversity, it is also necessary to update the model to reflect the fact that Ethereum is now technically two merged blockchains that operate in unison, the Beacon Chain which handles consensus, and the execution layer, which is the P2P layer that gossips transactions and handles execution.  For this reason, the original ``Client Decentralization'', and ``Node Decentralization'' metrics have been replaced by ``Consensus / Execution nodes by client / country'' metrics. 

The two metrics that have been retained in their original form are ``Distribution of native asset by amount'', which measures wealth inequality in terms of ownership of ETH, and ``Exchanges by supply'', which measures the potential influence of large centralized exchanges by the amount of ETH that they hold on deposit.

\subsection{Metrics pertaining to Proposer Builder Separation}

Our model introduces two new metrics that pertain to Proposer Builder Separation (PBS), which are ``Blocks proposed by builder'' and ``Blocks proposed by relay'' respectively.

PBS is a network topology that has not been implemented at the protocol level, but has been implemented via the mev-boost middleware developed by Flashbots \cite{gosselin2021}, and which came online at the time of Ethereum's switch to PoS.

Fundamentally, PBS allows for the separation of concerns between block building and block proposing \cite{ethereum2023}, whereas currently the protocol assigns the responsibility of both to the validator.  Ethereum's PoS protocol requires validators to broadcast a valid block of transactions to the network when they are selected as a proposer.  As per the specification, validators will build a block locally by requesting their local execution client to collate pending transactions from the public P2P network. However, validators can install mev-boost and can request blocks from third party specialist block builders via public relays, instead of building one themselves \cite{ethereum2022}.

This has several benefits, from lowering the resource requirements for running a validator node, to reducing centralizing economics of MEV in staking pools \cite{buterin2021}.  However, it also introduces a number of other actors into Ethereum's infrastructure topology, i.e. block builders and relays, creating new vectors for potential centralization.

\begin{figure}[h]
\centering

\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt    

\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
%uncomment if require: \path (0,225); %set diagram left start at 0, and has height of 225

%Shape: Rectangle [id:dp32874736422552087] 
\draw  [fill={rgb, 255:red, 204; green, 204; blue, 204 }  ,fill opacity=1 ] (40,90) -- (110,90) -- (110,130) -- (40,130) -- cycle ;
%Shape: Rectangle [id:dp7893810608134403] 
\draw  [fill={rgb, 255:red, 204; green, 204; blue, 204 }  ,fill opacity=1 ] (40,160) -- (110,160) -- (110,200) -- (40,200) -- cycle ;
%Shape: Rectangle [id:dp8757104876136521] 
\draw  [fill={rgb, 255:red, 204; green, 204; blue, 204 }  ,fill opacity=1 ] (40,20) -- (110,20) -- (110,60) -- (40,60) -- cycle ;
%Shape: Rectangle [id:dp7094759049141843] 
\draw   (140,90) -- (210,90) -- (210,130) -- (140,130) -- cycle ;
%Shape: Rectangle [id:dp6485665405686041] 
\draw   (140,160) -- (210,160) -- (210,200) -- (140,200) -- cycle ;
%Shape: Rectangle [id:dp9969164825616158] 
\draw   (240,160) -- (310,160) -- (310,200) -- (240,200) -- cycle ;
%Shape: Rectangle [id:dp3291661227641548] 
\draw   (140,20) -- (310,20) -- (310,60) -- (140,60) -- cycle ;
%Shape: Rectangle [id:dp44497942140930546] 
\draw   (240,90) -- (310,90) -- (310,130) -- (240,130) -- cycle ;
%Straight Lines [id:da5149384940052303] 
\draw    (240,180) -- (212,180) ;
\draw [shift={(210,180)}, rotate = 360] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da4997928601727849] 
\draw    (140,180) -- (112,180) ;
\draw [shift={(110,180)}, rotate = 360] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da05690888030284669] 
\draw    (40,180) -- (20,180) -- (20,30) -- (38,30) ;
\draw [shift={(40,30)}, rotate = 180] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da8057124336951804] 
\draw    (275,130) -- (275,157) ;
\draw [shift={(275,159)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da9723629842507198] 
\draw    (174,130) -- (174,142.5) -- (260,142.5) -- (260,158) ;
\draw [shift={(260,160)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da7759217148625789] 
\draw    (175,60) -- (175,88) ;
\draw [shift={(175,90)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da3789087953226402] 
\draw    (310,40) -- (330,40) -- (330,180) -- (312,180) ;
\draw [shift={(310,180)}, rotate = 360] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da45339092329104136] 
\draw    (76,90) -- (76,62) ;
\draw [shift={(76,60)}, rotate = 90] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da9969423372136927] 
\draw    (140,40.5) -- (126,40.5) -- (126,109.5) -- (112,109.5) ;
\draw [shift={(110,109.5)}, rotate = 360] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;

% Text Node
\draw (52,98) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {Execution\\ \ \ Client};
% Text Node
\draw (50,174) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {mev-boost};
% Text Node
\draw (50,28) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {Consensus\\ \ \ \ Client};
% Text Node
\draw (152,103) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {Searchers};
% Text Node
\draw (160,175) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {Relay};
% Text Node
\draw (243,174) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {Block Builder};
% Text Node
\draw (150,35) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {Ethereum Network \& Mempool};
% Text Node
\draw (251,97) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] { \ \ Private\\Orderflow};

\end{tikzpicture}

\caption{High level mev-boost architecture}
\label{fig:mev-boost architecture}
\end{figure}

Our model applies a weighting to the PBS metrics when considering the measurement in the context of Ethereum's overall level of decentralization.  This is because any byzantine behavior of the mev-boost middleware will result in validator nodes falling back to local block production, thus preventing any safety or liveness fault within the core protocol \cite{hasu2022}.

However, it has been well documented \cite{labrys2022} that a number of prominent mev-boost builders and relays actively censor transactions according to specific criteria.  This effectively results in those transactions experiencing a potentially significant delay in being included in a block, (about 68\% longer than regular transactions according to Yang et al. \cite{yang2022sok}). 

This can effectively create a two-tier network with transactions associated with certain addresses becoming ``less privileged'' than other transactions.  Ironically the more transactions that are censored in this way, the harder it is to censor them, as block builders will need to bid higher than the combined value of those transactions in order to have their blocks proposed, resulting in an effective per-block fee for censoring transactions \cite{buterin2022}.  However, the higher the level of centralization within the block builder / relay infrastructure, the greater the risk for censorship, creating increased barriers to participation in the network for affected users.

\subsection{Metrics pertaining to Account Abstraction}

Our model introduces two metrics that pertain specifically to account abstraction, including ``Number of user operations per bundler'' and ``Number of transactions per bundler''. Account Abstraction has been a goal of Ethereum since its inception, and there have been a number of previous proposals that were not implemented \cite{john2023, wilson2020, dietrichs2020}, which all involved some change to the core protocol.  The breakthrough came with ``ERC-4337: Account Abstraction Using Alt Mempool'' \cite{buterin2021B}, which does not require a protocol change, but which introduces new roles within the ecosystem topology: bundlers and paymasters.

ERC-4337 specifies a specific transaction type called a user operation, or ``userop''.  User operations are submitted to bundlers, who batch them into a single transaction to a global entrypoint contract, which iterates over the userops in the batch, passing them to their respective smart contract wallets along with the userop's calldata for the contract wallet to execute (e.g. send ETH or call a function on some specific smart contract).

\begin{figure}[h]
\centering

\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        

\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
%uncomment if require: \path (0,225); %set diagram left start at 0, and has height of 225

%Shape: Rectangle [id:dp7094759049141843] 
\draw   (20,75) -- (90,75) -- (90,115) -- (20,115) -- cycle ;
%Shape: Rectangle [id:dp6485665405686041] 
\draw   (120,75) -- (190,75) -- (190,115) -- (120,115) -- cycle ;
%Shape: Rectangle [id:dp920843516545626] 
\draw   (230,45) -- (300,45) -- (300,85) -- (230,85) -- cycle ;
%Shape: Rectangle [id:dp12494094437695702] 
\draw   (230,105) -- (300,105) -- (300,145) -- (230,145) -- cycle ;
%Shape: Rectangle [id:dp9780604775904197] 
\draw  [dash pattern={on 0.84pt off 2.51pt}] (220,20) -- (310,20) -- (310,170) -- (220,170) -- cycle ;
%Shape: Rectangle [id:dp4892691569318943] 
\draw  [dash pattern={on 0.84pt off 2.51pt}] (110,20) -- (200,20) -- (200,170) -- (110,170) -- cycle ;
%Straight Lines [id:da2517222890784073] 
\draw    (50,115) -- (50,135) -- (155.43,134.71) -- (155.43,116.71) ;
\draw [shift={(155.43,114.71)}, rotate = 90] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da7228274553126968] 
\draw    (154.43,74.71) -- (154.43,64.71) -- (227.43,64.71) ;
\draw [shift={(229.43,64.71)}, rotate = 180] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da29583642417688083] 
\draw    (265.43,85.71) -- (265.43,102.71) ;
\draw [shift={(265.43,104.71)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;

% Text Node
\draw (44,90) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {User};
% Text Node
\draw (137,90) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {Bundler};
% Text Node
\draw (116,173) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize,color={rgb, 255:red, 128; green, 128; blue, 128 }  ,opacity=1 ] [align=left] {Userop Mempool};
% Text Node
\draw (241,53) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {Entrypoint\\ \ Contract};
% Text Node
\draw (246,112) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {Contract\\ \ Wallets};
% Text Node
\draw (14,141) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {Submits Userops};
% Text Node
\draw (253,173) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize,color={rgb, 255:red, 128; green, 128; blue, 128 }  ,opacity=1 ] [align=left] {EVM};
% Text Node
\draw (116,33) node [anchor=north west][inner sep=0.75pt]  [font=\footnotesize] [align=left] {Submits Bundle\\Transaction};


\end{tikzpicture}

\caption{ERC-4337 Account Abstraction Architecture}
\label{fig:4337 architecture}
\end{figure}

Our model weights these metrics lower than other metrics within the model, as the risk posed from centralization within this class of actors is lower than other parts of the infrastructure we have included.  Although bundlers can choose to censor specific transactions, the censored sender can simply decide to send their transaction directly to the entry-point contract, or to their smart contract wallet directly, if its design allows.  This represents a relatively weak form of censorship, but it does require some user sophistication in order to bypass. Over-centralization in this part of Ethereum's infrastructure can potentially lead to censorship risks, resulting in an effective two-tier network, with some addresses being less privileged than others in terms of their access to the network. We posit that this is a reasonable basis for including this metric in our model, albeit with an adjusted weighting.

\subsection{Layer 2 Rollups by Relative TVL}

Our model introduces a metric to measure L2 Rollups by TVL relative to the TVL of the base layer.  As Ethereum progresses through its ``rollup-centric roadmap'' \cite{buterin2020}, the TVL of L2 rollups as proportionate to the overall network becomes more significant within the composition of the ecosystem.

Our model applies a weighting to this metric, taking into account the extent of the risk that centralization within these protocols pose, i.e. they may not cause a safety or liveness fault in the underlying protocol, but may nevertheless potentially cause loss of funds or significant delays should they be compromised.

Consider as an example an L2 rollup with a centralized sequencer that experiences a significant liveness fault, in which users with funds on that network are no longer able to transact as they would under normal conditions.  In this scenario, it may be possible that the users can force a withdrawal through the L2's base layer smart contract bridge.  However, if this rollup contains a substantial number of user accounts, it may result in significant congestion on the base layer \cite{gorzny2022ideal}.  This would likely cause an increase in base fee and a prolonged delay in transaction inclusion.  Furthermore, in the case of tokens that are minted natively on an L2, it may not be possible to withdraw them to the base layer at all.

There is also a theoretical risk to Ethereum's underlying social consensus from having a single dominant rollup is described by Buterin \cite{buterin2023}, from forming a broad assumption within the ecosystem that "\textit{if there is a bug that causes funds to be stolen, the losses will be so large that the community will have no choice but to fork to recover the users' funds}".

\subsection{Miscellaneous Metrics}

As part of our model we measure the \textbf{effective inflation rate adjusted for burn}.  This is an important metric for any PoS base layer protocol, including Ethereum.  A high rate of issuance of the network's native asset via validator rewards, has the effect of diluting the circulating supply, effectively decreasing the asset's value.  This incentivizes the network's users to stake the native asset in order to counteract the dilutionary effects of issuance, which forms a self-reinforcing cycle, leading to eventual hyperinflation even if that process takes a number of years.  Polynya describes a number of examples of this phenomenon that have been observed in practice \cite{polynya2022}. 

Our model thus incorporates a simple metric for measuring the inflation rate and adjusting it for the amount of ETH that is burned through the EIP-1559 mechanism, in which the base fee, which is adjusted for every block by the protocol itself, and that each transaction must pay at a minimum in order to be included in a block, is subsequently burned when a block is proposed.  This has the effect of  creating a negative issuance rate once transaction volume surpasses critical threshold, which will likely decrease the total supply over time \cite{liu2022empirical}.

We have also incorporated a closely related metric which is the \textbf{percentage of total supply staked}.  This is directly related to the effective inflation rate metric with respect to maintaining an economic equilibrium between the issuance rate and circulating supply, allowing the asset to hold its value over time \cite{john2021equilibrium}.  It is worth pointing out that Ethereum's economics are designed to maintain this equilibrium by reducing issuance as more validators come online \cite{edgington2023}, which theoretically reduces the incentive to stake once the percentage of staked assets reaches a certain threshold. However, there is always the possibility that innovations such as EigenLayer may disrupt this equilibrium over time.

Another meaningful metric that we have introduced into our model is the measurement of \textbf{Stablecoins by relative TVL on Ethereum}.  There exists both algorithmic stablecoins, (which are backed by a number of other assets and which rely on networks of decentralized oracles, and which are at least notionally decentralized by nature), and there also exists stablecoins which are backed largely by fiat deposits, and which are issued by a centralized authority.  The latter type of stablecoin is orthogonal to our model, insofar as while they are not part of the infrastructure of the network, they are a significant part of the ecosystem with which users interact with other dapps.  They also pose a centralization risk in terms of censorship as there have been a number of  cases where stablecoins have been frozen from specific addresses \cite{wall2021}.

\section{Methodology}

The measurement of inequality of distribution is a well understood area of statistics that has found many applications in the fields of economics and social sciences. There have been a number of studies in the field of cryptoeconomics that have made use of various popular statistical measurements.  As our model aims to measure the level of decentralization across a number of different dimensions with different qualities, we incorporate a number of different statistical measurements.

The various indices employed are useful in measuring distributions in different ways depending on what qualities of the distribution that are most relevant.  For example, the Gini index is arguably the most widely used index with regards to measuring wealth inequality, and is well suited for measuring the distribution of a network's native asset, (i.e. ETH), while the Herfindahl-Hirschman index is more often used for measuring the level of competition in specific industrial sectors, making it more suitable for measuring the degree of decentralization within the block builder market.

Furthermore, we have adopted certain indices for the purposes of identifying subtle changes in distributions over time, which common indices for measuring inequality do not always capture.

The indices that we have employed in our model are as listed below and are described in detail in the following sections.  Each index has characteristics and trade-offs associated with the underlying approach or model that they are based on.

\vspace{6pt}

\begin{center}
\begin{tabular}{|l|l|}
\hline
\textbf{Underlying Approach} & \textbf{Index} \\ \hline
Deviations model & Gini index \\ \hline
Combinatoratics model & Herfindahl-Hirschman index \\ \hline
Entropy model & Shannon index \\ \hline
Social welfare model & Atkinson index \\ \hline
Tail ratios & Palma ratio, Pareto ratio \\ \hline
Distance measures & Euclidean Distance \\ \hline
\end{tabular}
\end{center}

\vspace{2pt}

\subsection{Gini Index}

The Gini Index was developed by Corado Gini \cite{gini1936measure} as a mechanism for measuring inequality of income / wealth in a population, and is arguably the most commonly used measurement of inequality across a number of fields.   It is employed as the basis of the original Nakamoto Coefficient model, and has been used in several previous studies of decentralization in Bitcoin and/or Ethereum  \cite{sai2021characterizing, lee2021dq, gupta2018gini, kusmierz2022centralized, kwon2019impossibility, cong2023inclusion, gochhayat2020measuring, karakostas2022sok, zhang2022sok, campajola2022evolution}, which allows for some comparison with the results of previous studies.

The Gini Index is derived from the Lorenz curve \cite{lorenz1905methods}, which allows us to plot the individual shares of the distribution in relation to the overall total distribution.

\begin{figure}[h]

\begin{tikzpicture}
    \begin{axis}[
      xlabel = {cumulative proportion of population},
      ylabel = {cumulative proportion of resource},
      axis y line*=left,
      axis x line*=bottom,
      minor tick num=1,
      xmin = 0,
      xmax = 1,
      ymin = 0,
      ymax = 1
    ]
    \addplot[domain=0:1]{x} node[midway,above,sloped]{Line of equality};
    \node[anchor=north west] at (0.48,0.44) {A};
    \node[anchor=north west] at (0.7,0.22) {B};
    \addplot[domain=0:1,smooth, thick, label=$x$]{x^2}
      node[midway,below,sloped]{Lorenz curve};
    \end{axis}
\end{tikzpicture}

\caption{Visualization of Lorenz Curve}
\label{fig:lorenz-curve-graph}
\end{figure}


There are a number of different methods of calculating the Gini Index (Tutberidze et al. describe four \cite{tutberidze2018measuring}), though most methods are based on the calculation of the Lorenz Curve of a population, whereby the Gini index is calculated as the area between the line of equality and the Lorenz curve, divided by the total area under the line of equality, i.e.: \(G=\frac{A}{A+B}\)

While the area under a curve is commonly calculated using the Newton-Leibnitz formula \cite{kalinski2016} , where $L(x)$ is the Lorenz curve.  It can also be approximated as the sum of the areas of a series of trapeziums, correlating in width to the unit interval being measured. 
\[G=1-2\int_{0}^{1}L\left( x \right)dx\]

While the calculation of the Gini Index using the Lorenz Curve is useful for visualising the distribution and level of inequality on a chart, it is possible to calculate directly using an approach that is based on the empirical mean difference of the values in the dataset \cite{gastwirth1972estimation}:

\[G=\frac{\sum_{i=1}^{n}\sum_{j=1}^{n}\left| x_i - x_j \right|}{2n^2\mu}\]

The Gini index gives us a value of between 0 and 1, where 0 indicates perfect equality of distribution of resources within the population, and 1 is total inequality, i.e. one single entity controls 100\% of the resources.

\subsection{Atkinson Index}

The Gini Index is useful as a base for calculating inequality, but it has limitations in describing the \textit{qualities} of inequality.  As the Gini Index is based on the ratio of total areas under the curve, it does not account for variance or skewness, and it also means that two different distributions can potentially have the same Gini index, which could potentially affect the tracking of changes over time.

For this reason, our model employs the Atkinson index \cite{atkinson1970measurement} as a further measure of decentralization, to allow us to cross-reference our Gini index against a measurement that can be fine-tuned to our requirements, and which can be used to capture  any nuance in the distribution of different measurements.

The Atkinson index is based on the social-welfare approach, which at a high level tracks the amount of resources that would need to be redistributed to achieve a certain level of equality.  The Atkinson index is calculated using the following formula:

\[A(\varepsilon) = 1 - \left(\frac{1}{N} \sum_{i=1}^{N} \left(\frac{y_i}{\mu}\right)^{1 - \varepsilon}\right)^{\frac{1}{1 - \varepsilon}}, \quad \quad \varepsilon \neq 1
\]

\[A\left( \varepsilon \right)=1-\frac{\prod_{i=1}^{N}\left( y_{i}^{\frac{1}{N}} \right)}{\mu}, \quad \quad \varepsilon=1\]

\vspace{12pt}

where the parameters include:

\vspace{6pt}

\begin{center}
\begin{tabular}{|l|l|}
\hline
$\epsilon$ & inequality aversion parameter where $\epsilon>0$ \\ \hline
$n_{i}$ & number of people in the $i^{th}$ income group \\ \hline
N & total number of people \\ \hline
$y_{i}$ & average income of the $i^{th}$ income group \\ \hline
$\mu$ & average income of the total population \\ \hline
\end{tabular}
\end{center}

\vspace{6pt}

The Atkinson index is very closely linked to the generalized entropy index, and other related entropy based indices, such as the Theil index (i.e. GE(1)).  The Atkinson index results in a value between 0 and 1, and takes as a parameter $\epsilon$, which allows us to fine-tune the formula by increasing the value of $\epsilon$ in order to make the index more sensitive to changes at lower end of the distribution.  The value of $\epsilon$ is referred to as the inequality aversion, and yields a higher value when $\epsilon$ is given a value closer to 1.

\subsection{Herfindahl-Hirschman Index}

The Herfindahl-Hirschman Index is commonly used as a measurement of competition within a certain industry sector. It has found applications in regulation, particularly with antitrust authorities \cite{usdoj2015}. It is calculated as the sum of the square of the percentage market share of each entity in a sector.

As the HHI is based on percentage shares of the market, it becomes close to zero for a market that has been commoditized, having a large number of participants with a relatively equal share.  Conversely, the HHI approaches 10,000 for a highly concentrated market, with 10,000, (or $1 \times 100^2 $), being a single entity monopoly.

Our model adapts the standard HHI by re-scaling it to make it comparable with other indices employed in the model, by dividing the HHI by $10^4$ so that it falls in the interval $0 <= HHI <= 1$. As such, the re-scaled HHI, denoted by $\theta$, is expressed via the following formula, where $n$ is the total number of participants in the market, $P$ is the total number of units produced in the entire market, and $p_i$ is the number of units consumed from $i^{th}$ participant.

\[\theta = \sum_{i=1}^{n} \frac{(p_{i}/P \cdot 100)^{2}}{10^{4}}
\]

As an example, in measuring concentration in the block building market, $P$ would be the total number of blocks produced in an interval,  $p_i$ would be the blocks proposed to the network that are built by the $i^{th}$ block builder.

The US DoJ generally classifies markets within three discrete categories \cite{usdoj2015}:

\begin{center}
\begin{tabular}{|l|l|}
\hline
Unconcentrated & $HHI < 1,500$  \\ \hline
Moderately Concentrated & $1,500 <= HHI <= 2,500$ \\ \hline
Highly Concentrated & $HHI > 2,500$ \\ \hline
\end{tabular}
\end{center}

Because the Herfindahl-Hirschman Index is commonly used for identifying and measuring the presence of monopolies in industry, it is more suited to the datapoints in our model that measure the infrastructure that is provide as a service or public good by a relatively small number of actors, as opposed to measuring the distribution of ownership or control of some asset.  This makes it particularly useful for measuring middleware such as block builders or relays.

\subsection{Shannon Index}

The Shannon Index \cite{shannon1998mathematical} is part of a family of measurements that are derived from information theory and which are based on the concept of entropy.  Other measurements in this category include the Generalized Entropy measurement, and the Theil indices.

The Shannon index is a measure of the amount of entropy in a dataset.  It was intended to be used to measure the amount of information content in a signal, where information content can be considered as a measurement of the unexpectedness of a particular value occurring at a specific point in the signal, and entropy is the \textit{average} level of unexpectedness within a signal.  

Shannon gives examples of strings of characters, where the more characters and randomness there is, the lower the probability of predicting the next character in the string, and the more unexpected it is when that value occurs as predicted.  The less often the next character can be predicted correctly, the higher the entropy.

A basic example of this concept is a coin toss, where one party chooses heads, and where there is a 50\% chance of the expected value (i.e. heads) occurring as predicted.  As this has a relatively high probability, $p(heads) = 0.5$, coin tosses have low entropy. If we roll a die, the entropy increases as the probability of an expected value decreases, e.g. $p(6) = 0.16$.

Entropy as applied within the field of economics was systematized by Theil \cite{theil1967economics}, and has found applications in measuring inequality within a distribution of resources, and later within several studies of decentralization in cryptocurrencies \cite{zhang2022sok, gochhayat2020measuring, kusmierz2022centralized}.

The Shannon index is commonly expressed using the following formula, where $Ni$ is the frequency of a each value in the dataset divided by $N$, the total number of distinct values in the dataset, i.e. $N_i$ is the number of entities within the population that have a $i$ amount of resources, in proportion to $N$ total number entities in the population.

\[H' = - \sum_{i=1}^{N} \left(\frac{N_i}{N}\right) \log_{e} \left(\frac{N_i}{N}\right)\]

The Shannon index was designed for use with categorical data, as opposed to continuous data, for which the  GE index is better suited \cite{tran2021harnessing}.   However, for the purposes of measuring distribution of native asset (i.e. ETH), we have applied the Shannon index to ranges of amounts of ETH.  In this context, $p_i$ is the proportion of the asset owned by the $i^{th}$ percentile of the population.

The Shannon index has a range between 0 and the logarithm of the number of categories in the dataset, i.e. $0<=H'<=log(n)$.  The more centralized a system becomes, the closer the Shannon index will be to zero \cite{kusmierz2022centralized}.

\subsection{Tail Ratios}

According to Atkinson \cite{atkinson1970measurement}, the Gini index is affected by changes closer to the median of the distribution more than it is affected by changes at tail ends of the distribution.  In order to account for this characteristic of the Gini index, we employ a series of tail ratios to highlight any changes in the shape of the distribution that affect the lower and upper percentiles.

Our model incorporates the Palma Ratio\cite{palma2011homogeneous}, which is the ratio of the share of resources allocated to the top 10\% of the distribution to the lower 40\% of the distribution.  Palma concludes that changes in the level of inequality tend to happen more at either end of the distribution, with the middle being affected less.

We complement the Palma ratio with other inter-decile ratios that can be used to qualify the character of the inequality in the distribution, including the P90:P10, P50:P10 ratios.  These inter-decile ratios are calculated using the linear interpolation method \cite{frost2023B} described below, where $P_x$ denotes the desired percentile, and $N$ is the population size, a $v$ represents the value at position $i$ in an ascending ordered dataset, where $i$ is calculated using the following formula:

\[ i = \frac{P_x\left( N+1 \right)}{100} \]

This gives us the rank position of the desired percentile, assuming the dataset is sorted in ascending order.  We then interpolate between the value at this rank position in the ordered dataset, and the value at the subsequent position, in order to attain each percentile in our desired inter-decile ratio:

\begin{align*}
P = \left( v_{\left\lfloor i+1 \right\rfloor} - v_{\left\lfloor i \right\rfloor}\right)(n \ \text{mod} \ 1) + v_{\left\lfloor i \right\rfloor} \ , & \ \ i \ \text{mod} \ 1 \neq 0 \\
P = v_i \ , & \ \ i \ \text{mod} \ 1 = 0
\end{align*}

\vspace{8pt}

These ratios are employed simply as a complement to the other indices in our model, as a method of identifying potential areas where the model may need to be fine-tuned to correctly track changes over time.  By themselves they are not useful measurements as the range within the results are not bounded, as with the Gini index, or Herfindahl-Hirschman Index.

\subsection{Jensen-Shannon Divergence}

Let $p$ and $q$  be two probability distributions represented as vectors of sizes $n$ and $m$ respectively. If $n < m$,  pad $p$ with zeros until it matches the size of $q$. Similarly, if $m < n$, pad $q$ with zeros until it matches the size of $p$. We now have two vectors of the same size.

The normalized JS divergence is given by:


\[ D_{JS}(p||q) = \frac{1}{\log(2)} \left( \frac{1}{2} D_{KL}(p||m) + \frac{1}{2} D_{KL}(q||m) \right) \]

\vspace{8pt}

where $m = \frac{1}{2} (p + q)$  is the average of $p$ and $q$, and $D_{KL}(p||m)$ and $D_{KL}(q||m)$ are the Kullback-Leibler divergences of $p$ and $q$  from $m$ respectively, defined as:

\[
D_{KL}(p||q) = \sum_{i=1}^{n} p(i) \log \frac{p(i)}{q(i)}
\]

\vspace{8pt}


\subsection{Euclidean Distance}

As we are interested in measuring the changes to levels of decentralization over time, we employ the Euclidean Distance measurement as a way to track changes over discrete intervals.  In order to do this, we apply the Euclidean Distance measurement to the allocation of resources to either single entities, or discrete ranges of asset ownership, depending on the dataset, from one interval to the following interval.

As we derive a set of Euclidean Distances for each interval, we are particularly looking at the maximum distance that occurs between two intervals, which we have parameterized to 24 hours.  As such, we adapt the Euclidean Distance formula in our model to derive the maximum ED per measurement dimension per interval, using the following formula, where $m_1, m_2, \dots m_n$ is the set of metrics in each interval, $k$ and $k+1$ are the intervals being measured, $n$ is the number of values in the metric $m_{i,k}$

\[
\delta_{m,k} = \sqrt{\sum_{i=1}^{n} (m_{i,k} - m_{i,k-1})^2}
\]
\[
\rho = \max \left\{ \delta_{m_1,k}, \ \delta_{m_2,k}, \ \dots \ \delta_{m_n,k} \right\}
\]


\vspace{8pt}

The Euclidean Distance, as well as similar measurements, have been employed in previous research of decentralization in blockchain networks in previous studies \cite{gochhayat2020measuring}, in relation to measuring governance in decentralized networks. Our model employs this measurement as a means to identify changes in decentralization over time.

\subsection{Deriving a Master Index}

In order to measure Ethereum's level of decentralization over time, we need to account for it's modular topology, in which significant components of it's infrastructure will change.  For example, we might measure the concentration in the mev-boost relay market, but later decide to remove this metric as innovations like enshrined PBS make them redundant \cite{neuder2023}.

Our model calculates an aggregate set of indices across a number of dimensions of measurement, that can be used as an indicator of the relative level of decentralization in Ethereum as it changes over time.  Each relevant index, (i.e. Gini, HHI, Atkinson), has an associated aggregate index that is derived from calculating the normalized weighted geometric mean of that index's value across all relevant metrics, i.e.:

\[ \gamma = \frac{{\left(\prod_{i=1}^{n} (\beta_i \times \omega_i)\right)^{\frac{1}{n}} - \text{min}\left(\beta\right)}}{{\text{max}\left(\beta\right) - \text{min}\left(\beta\right)}} \]

\vspace{8pt}

where \(\beta=\{\text{index}_1, \text{index}_1, ..., \text{index}_n\}\) i.e. the set of relevant indices, $\omega$ is the respective weighting for each index, and $n=\left| \beta \right|$, the cardinality of $\beta$, or the number of metrics being measured.

\hfill

The relevant metrics that are included in each aggregate index, along with their respective weightings, are listed below. The weightings are assigned based on the qualitative properties of the infrastructural component being measured, as described in section III.

\vspace{12pt}

\begin{table}[h]
\normalsize
\begin{center}
\begin{tabular}{|l|c|}
\hline
\textbf{Metric} & \textbf{Weight} \\ \hline
Consensus nodes by client & 1 \\ \hline
Consensus nodes by country & 1 \\ \hline
Execution nodes by client & 1 \\ \hline
Execution nodes by country & 1 \\ \hline
Exchanges by supply & 0.7 \\ \hline
Distribution of ETH by amount & 1 \\ \hline
Amount staked by Pool & 1 \\ \hline
Blocks proposed by builder & 0.7 \\ \hline
Blocks proposed by relay & 0.7 \\ \hline
Number of userops per bundler & 0.2 \\ \hline
Number of transactions per bundler & 0.2 \\ \hline
Layer 2 rollups by relative TVL & 0.5 \\ \hline
Stablecoins by relative TVL & 0.3 \\ \hline
\end{tabular}
\end{center}
\end{table}

\vspace{6pt}

This results in a series of aggregate indices for each interval within the time-range our sample data is taken from.  The aggregate indices relate to the Gini, Atkinson, Normalized HHI and Normalized Shannon indices.  This should allow us to track the changes in decentralization over time, while allowing us to examine an individual index at specific intervals in order to further understand any changes that occur.

\printbibliography

\newpage

\onecolumn

\section{Appendix: List of Data Sources}

\vspace{12pt}

The following table lists the various sources of data for each data point that is referenced in our model.  The data from these sources were recorded programmatically and compiled into a database using software that was specifically designed for that purpose.

\vspace{24pt}

\begin{table*}[ht]
\normalsize
\begin{tabular}{ll}
\multicolumn{2}{l}{\textbf{Based on original Nakamoto Coefficient subsystem selection:}} \\[10pt]
Consensus nodes by client & \url{https://migalabs.es/api/v1/client-distribution} \\[6pt]
Consensus nodes by country & \url{https://migalabs.es/api/v1/geo-distribution} \\[6pt]
Execution nodes by client & \url{https://www.ethernodes.org/} \\[6pt]
Execution nodes by country & \url{https://www.ethernodes.org/countries} \\[6pt]
Exchanges by supply & \url{https://data.messari.io/api/v1/assets/ethereum/metrics} \\[6pt]
Distribution of native asset by amount & \url{https://data.messari.io/api/v1/assets/ethereum/metrics} \\[6pt]
Amount staked by Pool / Staking Service Provider & \url{https://api.dune.com/api/v1/query/2394100/results?api_key=} \\[24pt]
\multicolumn{2}{l}{\textbf{Metrics pertaining to Proposer Builder Separation:}} \\[10pt]
Blocks proposed by builder & \url{https://www.mevboost.org/stats} \\[6pt]
Blocks proposed by relayer & \url{https://www.relayscan.io/overview/md} \\[24pt]
\multicolumn{2}{l}{\textbf{Metrics pertaining to Account Abstraction:}} \\[10pt]
Number of user operations per bundler & \url{https://api.dune.com/api/v1/query/2490033/results?api_key=} \\[6pt]
Number of transactions per bundler & \url{https://api.dune.com/api/v1/query/2490033/results?api_key=} \\[24pt]
\multicolumn{2}{l}{\textbf{Miscellaneous Metrics:}} \\[10pt]
Rollups by relative TVL / size / volume & \url{https://l2beat.com/scaling/tvl} \\[6pt]
Stablecoins & \url{https://stablecoins.llama.fi/stablecoins} \\[6pt]
\end{tabular}
\end{table*}

\end{document}
